{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from faker import Faker\n",
    "import textwrap\n",
    "import xmltodict\n",
    "from itertools import chain, islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://faker.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://code.activestate.com/recipes/440546-chomsky-random-text-generator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CHOMSKY is an aid to writing linguistic papers in the style\n",
    "    of the great master.  It is based on selected phrases taken\n",
    "    from actual books and articles written by Noam Chomsky.\n",
    "    Upon request, it assembles the phrases in the elegant\n",
    "    stylistic patterns that Chomsky is noted for.\n",
    "    To generate n sentences of linguistic wisdom, type\n",
    "        (CHOMSKY n)  -- for example\n",
    "        (CHOMSKY 5) generates half a screen of linguistic truth.\"\"\"\n",
    "\n",
    "leadins = \"\"\"To characterize a linguistic level L,\n",
    "    On the other hand,\n",
    "    This suggests that\n",
    "    It appears that\n",
    "    Furthermore,\n",
    "    We will bring evidence in favor of the following thesis:\n",
    "    To provide a constituent structure for T(Z,K),\n",
    "    From C1, it follows that\n",
    "    For any transformation which is sufficiently diversified in application to be of any interest,\n",
    "    Analogously,\n",
    "    Clearly,\n",
    "    Note that\n",
    "    Of course,\n",
    "    Suppose, for instance, that\n",
    "    Thus\n",
    "    With this clarification,\n",
    "    Conversely,\n",
    "    We have already seen that\n",
    "    By combining adjunctions and certain deformations,\n",
    "    I suggested that these results would follow from the assumption that\n",
    "    If the position of the trace in (99c) were only relatively inaccessible to movement,\n",
    "    However, this assumption is not correct, since\n",
    "    Comparing these examples with their parasitic gap counterparts in (96) and (97), we see that\n",
    "    In the discussion of resumptive pronouns following (81),\n",
    "    So far,\n",
    "    Nevertheless,\n",
    "    For one thing,\n",
    "    Summarizing, then, we assume that\n",
    "    A consequence of the approach just outlined is that\n",
    "    Presumably,\n",
    "    On our assumptions,\n",
    "    It may be, then, that\n",
    "    It must be emphasized, once again, that\n",
    "    Let us continue to suppose that\n",
    "    Notice, incidentally, that \"\"\"\n",
    "# List of LEADINs to buy time.\n",
    "\n",
    "subjects = \"\"\" the notion of level of grammaticalness\n",
    "    a case of semigrammaticalness of a different sort\n",
    "    most of the methodological work in modern linguistics\n",
    "    a subset of English sentences interesting on quite independent grounds\n",
    "    the natural general principle that will subsume this case\n",
    "    an important property of these three types of EC\n",
    "    any associated supporting element\n",
    "    the appearance of parasitic gaps in domains relatively inaccessible to ordinary extraction\n",
    "    the speaker-hearer's linguistic intuition\n",
    "    the descriptive power of the base component\n",
    "    the earlier discussion of deviance\n",
    "    this analysis of a formative as a pair of sets of features\n",
    "    this selectionally introduced contextual feature\n",
    "    a descriptively adequate grammar\n",
    "    the fundamental error of regarding functional notions as categorial\n",
    "    relational information\n",
    "    the systematic use of complex symbols\n",
    "    the theory of syntactic features developed earlier\"\"\"\n",
    "# List of SUBJECTs chosen for maximum professorial macho.\n",
    "\n",
    "verbs = \"\"\"can be defined in such a way as to impose\n",
    "    delimits\n",
    "    suffices to account for\n",
    "    cannot be arbitrary in\n",
    "    is not subject to\n",
    "    does not readily tolerate\n",
    "    raises serious doubts about\n",
    "    is not quite equivalent to\n",
    "    does not affect the structure of\n",
    "    may remedy and, at the same time, eliminate\n",
    "    is not to be considered in determining\n",
    "    is to be regarded as\n",
    "    is unspecified with respect to\n",
    "    is, apparently, determined by\n",
    "    is necessary to impose an interpretation on\n",
    "    appears to correlate rather closely with\n",
    "    is rather different from\"\"\"\n",
    "#List of VERBs chosen for autorecursive obfuscation.\n",
    "\n",
    "objects = \"\"\" problems of phonemic and morphological analysis.\n",
    "    a corpus of utterance tokens upon which conformity has been defined by the paired utterance test.\n",
    "    the traditional practice of grammarians.\n",
    "    the levels of acceptability from fairly high (e.g. (99a)) to virtual gibberish (e.g. (98d)).\n",
    "    a stipulation to place the constructions into these various categories.\n",
    "    a descriptive fact.\n",
    "    a parasitic gap construction.\n",
    "    the extended c-command discussed in connection with (34).\n",
    "    the ultimate standard that determines the accuracy of any proposed grammar.\n",
    "    the system of base rules exclusive of the lexicon.\n",
    "    irrelevant intervening contexts in selectional rules.\n",
    "    nondistinctness in the sense of distinctive feature theory.\n",
    "    a general convention regarding the forms of the grammar.\n",
    "    an abstract underlying order.\n",
    "    an important distinction in language use.\n",
    "    the requirement that branching is not tolerated within the dominance scope of a complex symbol.\n",
    "    the strong generative capacity of the theory.\"\"\"\n",
    "# List of OBJECTs selected for profound sententiousness.\n",
    "\n",
    "def chomsky(times=1, line_length=72):\n",
    "    parts = []\n",
    "    for part in (leadins, subjects, verbs, objects):\n",
    "        phraselist = list(map(str.strip, part.splitlines()))\n",
    "        random.shuffle(phraselist)\n",
    "        parts.append(phraselist)\n",
    "    output = chain(*islice(zip(*parts), 0, times))\n",
    "    return textwrap.fill(' '.join(output), line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chomsky(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3877623/in-python-can-you-have-variables-within-triple-quotes-if-so-how\n",
    "htmlpage=\"\"\"\n",
    "<HTML>\n",
    "<TITLE>%s</TITLE>\n",
    "<BODY>\n",
    "%s\n",
    "</BODY>\n",
    "</HTML>\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_length=random.randint(5,8)\n",
    "# https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python\n",
    "#page_title=''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(title_length))\n",
    "\n",
    "page_title=\"observations on the role of \"+fake.job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordered_list(num_elements):\n",
    "    listbody=\"<ol>\\n\"\n",
    "    for indx in range(num_elements):\n",
    "        #list_text_length=random.randint(5,10)\n",
    "        #list_text=''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(list_text_length))\n",
    "        list_text=fake.catch_phrase()\n",
    "        listbody+=\"<LI>\"+list_text+\"</LI>\\n\"\n",
    "    return listbody+\"</ol>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_ordered_list(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_link():\n",
    "    #url_length=random.randint(15,25)\n",
    "    #domain=''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(url_length))\n",
    "    return \"<img src=\\\"\"+fake.image_url(width=None, height=None)+\"\\\">\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_image_link())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link(link_text):\n",
    "    #url_length=random.randint(10,15)\n",
    "    #domain=''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(url_length))\n",
    "    #return \"<a href=\\\"http://www.\"+domain+\".com\\\">\"+link_text+\"</a>\"\n",
    "    return \"<a href=\\\"\"+fake.url(schemes=None)+\"\\\">\"+link_text+\"</a>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_link(\"my great text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_to_text(txt):\n",
    "    txt_as_list=txt.split(' ')\n",
    "    word_to_replace=random.choice(txt_as_list)\n",
    "    create_link(word_to_replace)\n",
    "    return txt.replace(word_to_replace, create_link(word_to_replace),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_body():\n",
    "    body_text=add_link_to_text(\"<P>\"+chomsky(random.randint(2,4))+\"</P>\\n\")\n",
    "    body_text+=create_ordered_list(random.randint(3,5))\n",
    "    body_text+=create_image_link()+\"\\n\"\n",
    "    body_text+=add_link_to_text(\"<P>\"+chomsky(random.randint(2,4))+\"</P>\\n\")\n",
    "    body_text+=create_ordered_list(random.randint(3,5))\n",
    "    body_text+=create_image_link()+\"\\n\"\n",
    "    body_text+=add_link_to_text(\"<P>\"+chomsky(random.randint(2,4))+\"</P>\\n\")\n",
    "    return body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(htmlpage % (page_title,create_body()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages={\n",
    "    'page_content':{\n",
    "        '@author':fake.last_name_female(),\n",
    "        'date':fake.date(pattern=\"%Y-%m-%d\", end_datetime=None),\n",
    "        'source':fake.url(schemes=None),\n",
    "        'content':{'#text':htmlpage % (page_title,create_body())}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/martinblech/xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xmltodict.unparse(my_pages, pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_all={}\n",
    "my_pages_all['all_pages']={}\n",
    "\n",
    "for this_page_indx in range(125):\n",
    "    this_page={}\n",
    "    this_page['@author']=fake.last_name_female()\n",
    "    this_page['date']=fake.date(pattern=\"%Y-%m-%d\", end_datetime=None)\n",
    "    this_page['source']=fake.url(schemes=None)\n",
    "    page_title=\"observations on the role of \"+fake.job()\n",
    "    this_page['content']={'#text':htmlpage % (page_title,create_body())}\n",
    "    page_indx=''.join(random.choice(string.ascii_lowercase) for x in range(10))\n",
    "    my_pages_all['all_pages'][page_indx]=this_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xml_containing_html.xml','w') as fxml:\n",
    "    fxml.write(xmltodict.unparse(my_pages_all, pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
