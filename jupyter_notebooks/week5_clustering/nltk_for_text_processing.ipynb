{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.bradezone.com/2008/09/13/boring/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_text=\"I go to the store. A car is parked. \\\n",
    "Many cars are parked or moving. Some are blue. \\\n",
    "Some are tan. They have windows. In the store, \\\n",
    "there are items for sale. These include such \\\n",
    "things as soap, detergent, magazines, and lettuce. \\\n",
    "You can enhance your life with these products. \\\n",
    "Soap can be used for bathing, be it in a bathtub \\\n",
    "or in a shower. My email address is myname@sc.edu. \\\n",
    "Apply the soap to your body and rinse. My phone \\\n",
    "number is 452-953-2942. Detergent is used to \\\n",
    "wash clothes. Place your dirty clothes \\\n",
    "into a washing machine and add some detergent \\\n",
    "as directed on the box. Your email is \\\n",
    "aperson@farm.com and your cell is 595-942-2424. \\\n",
    "Select the appropriate settings on your \\\n",
    "washing machine and you should be ready to \\\n",
    "begin. Magazines are stapled reading material \\\n",
    "made with glossy paper, and they cover a wide \\\n",
    "variety of topics, ranging from news and \\\n",
    "politics to business and stock market information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize_list = sent_tokenize(this_text)\n",
    "sent_tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_sent in sent_tokenize_list:\n",
    "    word_tokens = word_tokenize(this_sent) \n",
    "    print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a one-time action to get a list of stopwords for NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_sent in sent_tokenize_list:\n",
    "    filtered_sentence = [] \n",
    "    word_tokens = word_tokenize(this_sent) \n",
    "    for w in word_tokens: \n",
    "        if w not in en_stops: \n",
    "            filtered_sentence.append(w) \n",
    "    print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
